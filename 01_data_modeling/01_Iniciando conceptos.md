## 1.1 ¬øQu√© es un DataFrame en Spark?

Un DataFrame es:

> Una colecci√≥n distribuida de filas (rows) organizadas en particiones

No es una tabla:

- No es un array  
- No es una lista  
- No es una base de datos  
- Es un **RDD optimizado + esquema**

### Modelo real

```text
DataFrame
 ‚îú‚îÄ‚îÄ Partition 1 ‚Üí rows
 ‚îú‚îÄ‚îÄ Partition 2 ‚Üí rows
 ‚îú‚îÄ‚îÄ Partition 3 ‚Üí rows
 ‚îî‚îÄ‚îÄ Partition N ‚Üí rows
```
## üîπ 1.2 Componentes reales

a) Schema (estructura l√≥gica)

El schema define c√≥mo Spark interpreta los datos:
- nombres de columnas  
- tipos de datos  
- nullabilidad  
- estructura (simple o compleja)
```text
Ejemplo:

df.printSchema()

Salida t√≠pica:
root
 |-- user_id: long (nullable = false)
 |-- country: integer (nullable = true)
 |-- event_type: integer (nullable = true)
 |-- value: double (nullable = true)
```
Esto representa la estructura l√≥gica del DataFrame.

---

b) Particiones (distribuci√≥n f√≠sica)

Las particiones definen c√≥mo los datos se distribuyen f√≠sicamente en el cluster.  
Cada partici√≥n = 1 unidad de ejecuci√≥n (task).
```text
Ejemplo:

print("N√∫mero de particiones:", df.rdd.getNumPartitions())

Ver tama√±o por partici√≥n:

df.rdd.glom().map(len).collect()

Salida ejemplo:
[50000, 50000, 50000, 50000, ...]
```
Esto muestra la distribuci√≥n f√≠sica real de los datos.

---

c) Linaje (DAG)

El linaje es el grafo de transformaciones que Spark construye internamente para ejecutar el job.  
No ejecuta nada hasta que hay una acci√≥n (count(), show(), write(), etc).

Ejemplo:

df2 = df.filter("value > 0.5").select("user_id", "country")

Ver linaje l√≥gico/f√≠sico:

df2.explain(mode="formatted")

Esto muestra:
- Plan l√≥gico
- Plan optimizado
- Plan f√≠sico
- DAG de ejecuci√≥n real

---

Modelo mental correcto:

Schema = c√≥mo se ve el dato  
Particiones = d√≥nde vive el dato  
DAG = c√≥mo se procesa el dato
